# -*- coding: utf-8 -*-
"""token.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jbgAMBZhbYTQNjd74zjYuFT0xVLhKkvb
"""

! pip install transformers

import torch
import numpy as np
import pandas as pd
import tensorflow as tf

from transformers import BertTokenizer
from transformers import BertForSequenceClassification
from transformers import TFBertForMaskedLM
from transformers import AutoTokenizer
from keras.preprocessing.sequence import pad_sequences


"""## **전처리**"""

# 데이터 로드
train = pd.read_csv("samples4.csv", sep = '\t')
# test_data = pd.read_csv("")
print(train.shape)
#print(test.shape)

train.head(10)

sentence = train['review']
sentence[:10]

# [CLS]는 문장의 시작에 사용
# [SEP]는 문장의 끝이나 두 문장 분리에 사용

sentence = ["[CLS] " + str(i) + " [SEP]" for i in sentence ]
sentence[:10]

# Bert-base의 토크나이저로 문장을 토큰으로 분리
tokenizer = BertTokenizer.from_pretrained("bert-base-multilingual-cased")
tokenized = [tokenizer.tokenize(i) for i in sentence]

print(tokenized[0])

# 토큰을 숫자 인덱스로 변환
input = [tokenizer.convert_tokens_to_ids(i) for i in tokenized]

# 문장을 max_len 길이에 맞게 자르고 모자란 부분은 0으로 채움
input = pad_sequences(input, maxlen = 500, dtype = "long", truncating = "post", padding = "post")
input[0]

# Attention mask 생성
# 패딩에 해당하는 부분은 0으로 패딩이 아닌 부분은 1로 간주하는 마스크 생성







"""## **모델 생성**"""

# GPU 디바이스 이름 구함
device_name = tf.test.gpu_device_name()

# GPU 디바이스 이름 검사
if device_name == '/device:GPU:0':
    print('Found GPU at: {}'.format(device_name))
else:
    raise SystemError('GPU device not found')

# 디바이스 설정
if torch.cuda.is_available():
  device = torch.device("cuda")
else:
  device = torch.device("cpu")

# BERT 모델 생성
model = BertForSequenceClassification.from_pretrained("bert-base-multilingual-cased", num_labels=2)
model.cuda()

# optimizer 설정 => optimizer는 AdamW

optimizer = torch.optim.AdamW(model.parameters(), lr = 2e-5)

epochs = 10

# 스케줄러 생성(학습률을 조금씩 감소)

# 학습
for i in range(epochs):

