{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "RenU6cJkKiUF",
    "outputId": "bed4cb99-247d-4a35-e20a-324eea9d61d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
      "  Using cached urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
      "Installing collected packages: urllib3\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.9\n",
      "    Uninstalling urllib3-1.26.9:\n",
      "      Successfully uninstalled urllib3-1.26.9\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "selenium 4.1.3 requires urllib3[secure,socks]~=1.26, but you have urllib3 1.25.11 which is incompatible.\n",
      "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "Successfully installed urllib3-1.25.11\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "urllib3"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /usr/local/lib/python3.7/dist-packages (4.1.3)\n",
      "Collecting urllib3[secure,socks]~=1.26\n",
      "  Using cached urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.7/dist-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.7/dist-packages (from selenium) (0.20.0)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.10)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: outcome in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (1.1.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.7/dist-packages (from trio-websocket~=0.9->selenium) (1.1.0)\n",
      "Requirement already satisfied: cryptography>=1.3.4 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium) (36.0.2)\n",
      "Requirement already satisfied: pyOpenSSL>=0.14 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium) (22.0.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium) (2021.10.8)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.13.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from h11<1,>=0.9.0->wsproto>=0.14->trio-websocket~=0.9->selenium) (3.10.0.2)\n",
      "Installing collected packages: urllib3\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.25.11\n",
      "    Uninstalling urllib3-1.25.11:\n",
      "      Successfully uninstalled urllib3-1.25.11\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.9 which is incompatible.\n",
      "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "Successfully installed urllib3-1.26.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "urllib3"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "! pip install transformers\n",
    "! pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fggtE7wuloJU",
    "outputId": "f8add63b-284e-4c09-9fb4-8cffa3ab4d4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
      "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
      "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
      "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
      "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
      "Get:6 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
      "Hit:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
      "Hit:9 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
      "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
      "Hit:12 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
      "Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
      "Hit:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
      "Hit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
      "Fetched 252 kB in 3s (90.2 kB/s)\n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "chromium-chromedriver is already the newest version (99.0.4844.84-0ubuntu0.18.04.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 40 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!apt-get update\n",
    "!apt install chromium-chromedriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uxhM6KdFpjY3",
    "outputId": "edddc9ed-9517-4126-adf7-da2f443c05ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n"
     ]
    }
   ],
   "source": [
    "!cp /usr/lib/chromium-browser/chromedriver /usr/bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LsqRL7b5loQU",
    "outputId": "ec253568-0cdd-47d1-9189-64883dd752bd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: DeprecationWarning: use options instead of chrome_options\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "페이지 1 \n",
      "\n",
      "페이지 2 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 패키지 import\n",
    "import os\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "d = webdriver.Chrome('chromedriver', chrome_options=chrome_options)\n",
    "\n",
    "'''\n",
    "s = Service('/content/chromedriver.exe')\n",
    "\n",
    "d = webdriver.Chrome(service = s)\n",
    "\n",
    "'''\n",
    "\n",
    "name = ['에어팟 1세대', '에어팟 2세대']\n",
    "\n",
    "\n",
    "# 쇼핑몰 검색\n",
    "link = \"https://search.shopping.naver.com/catalog/16233352105?NaPm=ct%3Dl1vtwy7k%7Cci%3Da2cc9438d6415f5c49377e2e7760e09349687ad4%7Ctr%3Dslcc%7Csn%3D95694%7Chk%3Db9076c74953a2f0f7ddee6918d7b29798432fa16\"\n",
    "# xpath\n",
    "shoppingmall_review = \"/html/body/div/div/div[2]/div[2]/div[2]/div[3]/div[2]/div/div[2]/ul/li[3]/a/strong\"\n",
    "all_review = \"/html/body/div/div/div[2]/div[2]/div[2]/div[3]/div[5]/div[2]/div[2]/ul/li[1]/a\"\n",
    "\n",
    "header = {'User-Agent': ''}\n",
    "\n",
    "d.implicitly_wait(3)\n",
    "d.get(link)\n",
    "req = requests.get(link)\n",
    "html = req.text\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "\n",
    "# 함수 선언\n",
    "def add_dataframe(stars, reviews, cnt):  # 데이터 프레임에 저장\n",
    "    # 데이터 프레임생성\n",
    "    df1 = pd.DataFrame(columns=['star', 'review'])\n",
    "    n = 1\n",
    "    if (cnt > 0):\n",
    "        for i in range(0, cnt - 1):\n",
    "            df1.loc[n] = [stars[i],reviews[i]]  # 해당 행에 저장\n",
    "            i += 1\n",
    "            n += 1\n",
    "    else:\n",
    "        df1.loc[n] = ['null', 'null']\n",
    "        n += 1\n",
    "    return df1\n",
    "\n",
    "\n",
    "def save():\n",
    "    if not os.path.exists('output1.csv'):\n",
    "        df1.to_csv('output1.csv', encoding='utf-8', mode='w')\n",
    "    else:\n",
    "        df1.to_csv('output1.csv', encoding='utf-8', mode='w', header=False)\n",
    "\n",
    "\n",
    "# 쇼핑몰 리뷰 보기\n",
    "d.find_element(By.XPATH, shoppingmall_review)\n",
    "\n",
    "sleep(2)\n",
    "\n",
    "# 전체 리뷰 가져오기\n",
    "d.find_element(By.XPATH, all_review).click()  # 스크롤 건드리면 안됨\n",
    "name_ = name[0]  # 에어팟 1세대\n",
    "reviews = []\n",
    "stars = []\n",
    "cnt = 1  # 리뷰index\n",
    "page = 1\n",
    "while True:\n",
    "    j = 1\n",
    "    print(\"페이지\", page, \"\\n\")\n",
    "    sleep(2)\n",
    "    while True:  # 한페이지에 20개의 리뷰, 마지막 리뷰에서 error발생\n",
    "        try:\n",
    "            star = d.find_element(By.XPATH, '/html/body/div/div/div[2]/div[2]/div[2]/div[3]/div[5]/ul/li[' + str(j) +']/div[1]/span[1]').text\n",
    "            stars.append(star)\n",
    "            review = d.find_element(By.XPATH,\n",
    "               '/html/body/div/div/div[2]/div[2]/div[2]/div[3]/div[5]/ul/li[' + str(j) +']/div[2]/div[1]/p').text\n",
    "            reviews.append(review)\n",
    "            if j % 2 == 0:  # 화면에 2개씩 보이도록 스크롤\n",
    "                ELEMENT = d.find_element(By.XPATH,\n",
    "                    '/html/body/div/div/div[2]/div[2]/div[2]/div[3]/div[5]/ul/li[' + str(j) +']/div[2]/div[1]/p')\n",
    "                d.execute_script(\"arguments[0].scrollIntoView(true);\", ELEMENT)\n",
    "            j += 1\n",
    "            #print(cnt, star, review, \"\\n\")\n",
    "            cnt += 1\n",
    "        except: break\n",
    "\n",
    "    sleep(2)\n",
    "\n",
    "    if page < 11:  # page10까지 적용\n",
    "        try:  # 리뷰의 마지막 페이지에서 error발생\n",
    "            next_page = d.find_element(By.XPATH, '/html/body/div/div/div[2]/div[2]/div[2]/div[3]/div[5]/div[3]/a[' + str(page) + ']').click()\n",
    "            page += 1\n",
    "        except: break  # 리뷰의 마지막 페이지에서 process 종료\n",
    "\n",
    "    else:\n",
    "        try:  # page11부터\n",
    "            if page % 10 == 0:\n",
    "                next_page = d.find_element(By.XPATH, '/html/body/div/div/div[2]/div[2]/div[2]/div[3]/div[5]/div[3]/a[12]').click()\n",
    "            else:\n",
    "                next_page = d.find_element(By.XPATH, '/html/body/div/div/div[2]/div[2]/div[2]/div[3]/div[5]/div[3]/a[' + str(page % 10 + 2) + ']').click()\n",
    "            page += 1\n",
    "        except: break\n",
    "\n",
    "    if cnt > 40: break\n",
    "\n",
    "  \n",
    "\n",
    "df1 = add_dataframe(stars, reviews, cnt)\n",
    "save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MXQDpVE7loTM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ExkSROHloV-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TE0R331iKpSf"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import requests\n",
    "import time\n",
    "import csv\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import TFBertForMaskedLM\n",
    "from transformers import AutoTokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qo7z2kASvvtf"
   },
   "source": [
    "## **전처리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4DUYRM5wLkMz"
   },
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "# 열 이름 추가해서 데이터로드\n",
    "train = pd.read_csv(\"/content/output1.csv\", names = [\"index\", \"rating\", \"review\",\"label\"])\n",
    "# test_data = pd.read_csv(\"\")\n",
    "print(train.shape)\n",
    "#print(test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FEsxIJukpSQu"
   },
   "outputs": [],
   "source": [
    "train.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G-pyz6HXpSSQ"
   },
   "outputs": [],
   "source": [
    "# 리뷰 본문만 출력\n",
    "sentence = train['Review']\n",
    "sentence[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sVUDX0M9pSTq"
   },
   "outputs": [],
   "source": [
    "# [CLS]는 문장의 시작에 사용\n",
    "# [SEP]는 문장의 끝이나 두 문장 분리에 사용\n",
    "\n",
    "sentence = [\"[CLS] \" + str(i) + \" [SEP]\" for i in sentence ]\n",
    "sentence[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#라벨 추출\n",
    "# 우리는 데이터에 라벨을 추가해야함\n",
    "labels = train['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mFDix4QqpncR"
   },
   "outputs": [],
   "source": [
    "# Bert-base의 토크나이저로 문장을 토큰으로 분리\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "tokenized = [tokenizer.tokenize(i) for i in sentence]\n",
    "\n",
    "print(tokenized[0])\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gm8p4eACpnjN"
   },
   "outputs": [],
   "source": [
    "# 토큰을 숫자 인덱스로 변환\n",
    "input = [tokenizer.convert_tokens_to_ids(i) for i in tokenized]\n",
    "\n",
    "# 문장을 max_len 길이에 맞게 자르고 모자란 부분은 0으로 채움\n",
    "input = pad_sequences(input, maxlen = 500, dtype = \"long\", truncating = \"post\", padding = \"post\")\n",
    "input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "msvNw2HfpIYF"
   },
   "outputs": [],
   "source": [
    "# Attention mask 생성\n",
    "# 패딩에 해당하는 부분은 0으로 패딩이 아닌 부분은 1로 간주하는 마스크 생성\n",
    "\n",
    "# 어텐션 마스크 초기화\n",
    "attention_masks = []\n",
    "\n",
    "for se in input:\n",
    "    seq_mask = [float(i>0) for i in se]\n",
    "    attention_masks.append(seq_mask)\n",
    "\n",
    "print(attention_masks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AAQgwzfqpRUS"
   },
   "outputs": [],
   "source": [
    "# 데이터를 텐서로 변환\n",
    "# train 비율과 validation의 비율이 9대 1\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input,\n",
    "                                                                                    labels, \n",
    "                                                                                    random_state=2018, \n",
    "                                                                                    test_size=0.1)\n",
    "\n",
    "# 어텐션 마스크를 훈련셋과 검증셋으로 분리\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, \n",
    "                                                       input,\n",
    "                                                       random_state=2018, \n",
    "                                                       test_size=0.1)\n",
    "\n",
    "# 데이터를 파이토치의 텐서로 변환\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "validation_masks = torch.tensor(validation_masks)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DAsAMG7rpRWq"
   },
   "outputs": [],
   "source": [
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler = train_sampler, batch_size = 100)\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mCHmk4ybpRZi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tq-MOc_JvlWe"
   },
   "source": [
    "## **모델 생성**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GuMr8v4BpRbg"
   },
   "outputs": [],
   "source": [
    "# GPU 디바이스 이름 구함\n",
    "device_name = tf.test.gpu_device_name()\n",
    "\n",
    "# GPU 디바이스 이름 검사\n",
    "if device_name == '/device:GPU:0':\n",
    "    print('Found GPU at: {}'.format(device_name))\n",
    "else:\n",
    "    raise SystemError('GPU device not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CweIqH2XpReF"
   },
   "outputs": [],
   "source": [
    "# 디바이스 설정\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device(\"cuda\")\n",
    "else:\n",
    "  device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XFvXZYdCLkVr"
   },
   "outputs": [],
   "source": [
    "# BERT 모델 생성\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=2)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K5yDJjIKKpad"
   },
   "outputs": [],
   "source": [
    "# optimizer 설정 => optimizer는 AdamW\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = 2e-5)\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "# 스케줄러 생성(학습률을 조금씩 감소)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ueKxs_VKKpdS"
   },
   "outputs": [],
   "source": [
    "# 학습\n",
    "for i in range(epochs):\n",
    "    model.train()\n",
    "    cost = 0 \n",
    "    \n",
    "    # 데이터로더에서 배치만큼 가져옴\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2H7zoe7eKpf7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "59M8xqHNKpkk"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "token.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
